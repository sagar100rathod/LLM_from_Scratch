{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab5c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([2, 4, 768])\n",
      "Output Shape: torch.Size([2, 4, 768])\n",
      "Input Shape: torch.Size([2, 4, 768])\n",
      "Output Shape: torch.Size([2, 4, 50257])\n",
      "Total Params: 163000320\n",
      "Token Embedding Layer Shape: torch.Size([50257, 768])\n",
      "Output Layer Shape: torch.Size([50257, 768])\n",
      "Total Size of the model (MB): 621.796875\n",
      "Encoded: [5211, 345, 760, 1997]\n",
      "tensor([[5211,  345,  760, 1997]]) torch.Size([1, 4])\n",
      "Ouput: tensor([[ 5211,   345,   760,  1997, 33031,  5494, 11095, 41083, 11123,  7258]])\n",
      "Decoded Text: Do you know anythingNewsletter hun DrugJane threateninguan\n"
     ]
    }
   ],
   "source": [
    "import ipynb\n",
    "\n",
    "# Runs the entire notebook\n",
    "from ipynb.fs.full.C3_LLM_architecture_GPT2 import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e480bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57ab11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569ec41",
   "metadata": {},
   "source": [
    "# Calculating Text Generation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc02aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Token IDs: [[2437, 389, 345], [2061, 318, 534]]\n",
      "Decoded Token IDs: ['How are you', 'What is your']\n",
      "tensor([[2437,  389,  345],\n",
      "        [2061,  318,  534]]) torch.Size([2, 3])\n",
      "tensor([[ 533,  345, 1804],\n",
      "        [ 271,  534, 1438]]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "input_texts = [\"How are you\", \"What is your\"]\n",
    "target_next_words = [\"are you doing\", \"is your name\"]\n",
    "\n",
    "tokens = [tokenizer.encode(text) for text in input_texts]\n",
    "print(\"Encoded Token IDs:\", tokens)\n",
    "print(\"Decoded Token IDs:\", [tokenizer.decode(token_ids) for token_ids in tokens])\n",
    "\n",
    "X = torch.tensor(tokens)\n",
    "print(X, X.shape) # batch size, seq length\n",
    "\n",
    "y = torch.tensor([tokenizer.encode(text) for text in target_next_words])\n",
    "\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412c597a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Probas shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Probas shape:\", probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54cb806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token ids shape: torch.Size([2, 3, 1])\n",
      "tensor([[[48299],\n",
      "         [15347],\n",
      "         [   14]],\n",
      "\n",
      "        [[37611],\n",
      "         [10752],\n",
      "         [37853]]])\n"
     ]
    }
   ],
   "source": [
    "predicted_token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Predicted token ids shape:\", predicted_token_ids.shape)\n",
    "print(predicted_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdba28da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.2766e-05, 1.3428e-05, 1.9073e-05]), torch.Size([3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch probabilities for only target token ids\n",
    "batch_index = 0 \n",
    "predicted_probas__target1 = probas[batch_index, [0, 1, 2], y[batch_index]]\n",
    "predicted_probas__target1, predicted_probas__target1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02f0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.3120e-05, 2.2787e-05, 1.9343e-05]), torch.Size([3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_index = 1\n",
    "predicted_probas__target2 = probas[batch_index, [0, 1, 2], y[batch_index]]\n",
    "predicted_probas__target2, predicted_probas__target2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc29a7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.2687, -11.2182, -10.8672, -10.6748, -10.6893, -10.8532])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((predicted_probas__target1, predicted_probas__target2)))\n",
    "log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c166a7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.9286)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "avg_log_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7bd6b",
   "metadata": {},
   "source": [
    "* The goal is to get the average log probability as close to 0 as possible by updating the model's weights as par part of training process. However, in deep learning, the common practice is not to push the average probability up to 0 but rather to bring the negative average log probability down to 0. The negative average log probability is simply the average log probability multiplied by -1\n",
    "\n",
    "* In deep learning, the term for turning this negative value into positive is knows as the cross_entropy loss.\n",
    "\n",
    "* the cross entropy loss is popular measure in deep learning that measures the difference between two probability distributions, typically the true distribution of labels and the predicted distribution from a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deefbe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9286)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_avg_log_probas = -1 * avg_log_probas\n",
    "neg_avg_log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc82bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Target shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f566a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Logits: torch.Size([6, 50257])\n",
      "Flattened Targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = y.flatten()\n",
    "print(\"Flattened Logits:\", logits_flat.shape)\n",
    "print(\"Flattened Targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b6e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9286)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4335a95",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "\n",
    "* Perplexity measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset.\n",
    "* Similar to the loss, a lower perplexity indicates that the model predictions are closer to the actual distribution.\n",
    "* Perplexity is calculated as = exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77f34c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55746.9727)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(loss) \n",
    "# this would translate to the model being unsure about which among 55746 tokens in the vocabulary to generate as the next token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b183e5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e6ae9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    text_data = fp.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Total tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad1b60",
   "metadata": {},
   "source": [
    "# Train and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1e0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * total_characters)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01cf1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "class GPTDatasetV1(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(text)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            x = token_ids[i: i + max_length]\n",
    "            y = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(x))\n",
    "            self.target_ids.append(torch.tensor(y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42f51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab79879",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(train_data, batch_size=2, max_length=GPT_CONFIG[\"context_length\"],\n",
    "                                    stride=GPT_CONFIG[\"context_length\"], drop_last=True, shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = create_dataloader_v1(val_data, batch_size=2, max_length=GPT_CONFIG[\"context_length\"],\n",
    "                                    stride=GPT_CONFIG[\"context_length\"], num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d084f447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dedc10a",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "935207e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256]) torch.Size([2, 256, 50257]) CE Loss: tensor(11.0315)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor):\n",
    "        \"\"\"\n",
    "        logits: Logits of shape BATCH_SIZE, SEQ_LENGTH, VOCAB_SIZE\n",
    "        target: Targets of shape BATCH_SIZE, SEQ_LENGTH\n",
    "        \"\"\"\n",
    "        logits_flatten = logits.flatten(start_dim=0, end_dim=1) # -> BATCH_SIZE * SEQ_LENGTH, VOCB_SIZE\n",
    "        target_flatten = target.flatten() # -> BATCH_SIZE * SEQ_LENGTH\n",
    "        return F.cross_entropy(logits_flatten, target_flatten)\n",
    "\n",
    "loss = CELoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X, y in val_loader:\n",
    "        logits = model(X)\n",
    "        print(X.shape, y.shape, logits.shape, \"CE Loss:\", loss(logits, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0132af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepml.tasks import NeuralNetTask\n",
    "\n",
    "model = GPTModel(GPT_CONFIG)\n",
    "\n",
    "task = NeuralNetTask(model, \"./model_wights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "164825ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepml.train import Learner\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "loss = CELoss()\n",
    "\n",
    "trainer = Learner(task, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee55a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation  : 100%|██████████| 1/1 [00:06<00:00,  6.15s/it, loss=7.5213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 9.1085 Validation Loss: 7.5213 [Saving best validation model]\n",
      "Epoch 2/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [02:48<00:00, 18.77s/it, loss=9.1085]\n",
      "Validation  : 100%|██████████| 1/1 [00:07<00:00,  7.01s/it, loss=6.5171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.4931 Validation Loss: 6.5171 [Saving best validation model]\n",
      "Epoch 3/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [03:59<00:00, 26.63s/it, loss=6.4931]\n",
      "Validation  : 100%|██████████| 1/1 [00:06<00:00,  6.61s/it, loss=6.5686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.7172 Validation Loss: 6.5686 \n",
      "Epoch 4/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [03:43<00:00, 24.79s/it, loss=5.7172]\n",
      "Validation  : 100%|██████████| 1/1 [00:07<00:00,  7.50s/it, loss=6.5142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 5.0226 Validation Loss: 6.5142 [Saving best validation model]\n",
      "Epoch 5/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [04:04<00:00, 27.21s/it, loss=5.0226]\n",
      "Validation  : 100%|██████████| 1/1 [00:08<00:00,  8.34s/it, loss=6.3687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.2584 Validation Loss: 6.3687 [Saving best validation model]\n",
      "Epoch 6/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [04:51<00:00, 32.39s/it, loss=4.2584]\n",
      "Validation  : 100%|██████████| 1/1 [00:06<00:00,  6.00s/it, loss=6.4018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.6118 Validation Loss: 6.4018 \n",
      "Epoch 7/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [03:17<00:00, 21.99s/it, loss=3.6118]\n",
      "Validation  : 100%|██████████| 1/1 [00:02<00:00,  2.44s/it, loss=6.3881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.9067 Validation Loss: 6.3881 \n",
      "Epoch 8/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [02:03<00:00, 13.74s/it, loss=2.9067]\n",
      "Validation  : 100%|██████████| 1/1 [00:02<00:00,  2.03s/it, loss=6.4239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.3299 Validation Loss: 6.4239 \n",
      "Epoch 9/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [01:13<00:00,  8.11s/it, loss=2.3299]\n",
      "Validation  : 100%|██████████| 1/1 [00:01<00:00,  1.96s/it, loss=6.5009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7235 Validation Loss: 6.5009 \n",
      "Epoch 10/10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [01:07<00:00,  7.49s/it, loss=1.7235]\n",
      "Validation  : 100%|██████████| 1/1 [00:01<00:00,  1.96s/it, loss=6.6728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3035 Validation Loss: 6.6728 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training    : 100%|██████████| 9/9 [01:21<00:00,  9.09s/it, loss=1.3035]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb447ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9deccfe670>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(10), trainer.history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(range(10), trainer.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"CE Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97e0d7",
   "metadata": {},
   "source": [
    "## Decoding Strategies To Control Randomness in Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc785f",
   "metadata": {},
   "source": [
    "### 1. Greedy Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22d75287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select next token always with max prob using argmax\n",
    "def generate_text_sample(model, idx, max_new_tokens, context_size):\n",
    "    model.eval()\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # last vector\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01c8458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text: how is this have learned that mighty up-stream stroke.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I turned back to my work, that one long\n"
     ]
    }
   ],
   "source": [
    "input_text = \"how is this\"\n",
    "input_token_ids = tokenizer.encode(input_text)\n",
    "input_token_ids = torch.tensor(input_token_ids).unsqueeze(dim=0) # add batch dimension, BATCH_SIZE, SEQ_LENGTH\n",
    "output_token_ids = generate_text_sample(model, input_token_ids,\n",
    "                                 max_new_tokens=25, context_size=GPT_CONFIG[\"context_length\"])\n",
    "\n",
    "output_token_ids = output_token_ids.squeeze(dim=0).tolist() # remove batch size\n",
    "print(\"Output Text:\", tokenizer.decode(output_token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2feb721",
   "metadata": {},
   "source": [
    "* Atleast, Better text generation than previously generated output with this trained model on sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d540c2",
   "metadata": {},
   "source": [
    "### 2. Temperature Scaling\n",
    "\n",
    "* a technique that adds a probabilistic selection process to the next-token generation task.\n",
    "* it is just a fancy description for dividing the logits by a number greater than 0.\n",
    "* Temperature greater than 1 results in more uniformly distributed token probabilities and temperatures smaller than 1 will result in more confident distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature: float = 1.0):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)\n",
    "\n",
    "# Select next token always with max prob using argmax\n",
    "def generate_text_sample_v2(model, idx, max_new_tokens, context_size, temperature):\n",
    "    model.eval()\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # last vector #logits of shape [BS, SEQ_LEGNTH, VOCAB_SIZE] => [1, 50257]\n",
    "        probas = softmax_with_temperature(logits, temperature)\n",
    "        idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Every effort moves\"\n",
    "input_token_ids = tokenizer.encode(input_text)\n",
    "input_token_ids = torch.tensor(input_token_ids).unsqueeze(dim=0) # add batch dimension, BATCH_SIZE, SEQ_LENGTH\n",
    "output_token_ids = generate_text_sample_v2(model, input_token_ids,\n",
    "                                 max_new_tokens=25, context_size=GPT_CONFIG[\"context_length\"], \n",
    "                                 temperature=5)\n",
    "\n",
    "output_token_ids = output_token_ids.squeeze(dim=0).tolist() # remove batch size\n",
    "print(\"Output Text:\", tokenizer.decode(output_token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d590aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text: Every effort moves spuriousseeing halves bumps growersOnce mortg ensure spirits corridors Confederate distinction vacuum rode Contact searchedgovernmentRoberprep hoholesIAS Diss nodded Poo\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Every effort moves\"\n",
    "input_token_ids = tokenizer.encode(input_text)\n",
    "input_token_ids = torch.tensor(input_token_ids).unsqueeze(dim=0) # add batch dimension, BATCH_SIZE, SEQ_LENGTH\n",
    "output_token_ids = generate_text_sample_v2(model, input_token_ids,\n",
    "                                 max_new_tokens=25, context_size=GPT_CONFIG[\"context_length\"], \n",
    "                                 temperature=5)\n",
    "\n",
    "output_token_ids = output_token_ids.squeeze(dim=0).tolist() # remove batch size\n",
    "print(\"Output Text:\", tokenizer.decode(output_token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa17f52",
   "metadata": {},
   "source": [
    "## Top-K Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c0594",
   "metadata": {},
   "source": [
    "* We can restrict the sampled tokens to the top-k most likely tokens and exlude all other tokens from the selection process by masking their probability scores.\n",
    "* The top-k approach replaces all nonselected logits with -inf such that when computing softmax, the probability scores on the non-top-k tokens are 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1203773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature: float = 1.0, topk: int = 5):\n",
    "    topk_logits, _ = torch.topk(logits, topk)\n",
    "    min_val = topk_logits[:, -1]\n",
    "\n",
    "    logits = torch.where(logits < min_val, -torch.inf, logits)\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)\n",
    "\n",
    "# Select next token always with max prob using argmax\n",
    "def generate_text_sample_v3(model, idx, max_new_tokens, context_size, temperature, topk:int = 10):\n",
    "    model.eval()\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # last vector\n",
    "        probas = softmax_with_temperature(logits, temperature, topk)\n",
    "        idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "177b756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text: Every effort moves you in withoutace up--that was, a face the last thing he wasity\"Oh--that was that it,\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Every effort moves\"\n",
    "input_token_ids = tokenizer.encode(input_text)\n",
    "input_token_ids = torch.tensor(input_token_ids).unsqueeze(dim=0) # add batch dimension, BATCH_SIZE, SEQ_LENGTH\n",
    "output_token_ids = generate_text_sample_v3(model, input_token_ids,\n",
    "                                 max_new_tokens=25, context_size=GPT_CONFIG[\"context_length\"], \n",
    "                                 temperature=5)\n",
    "\n",
    "output_token_ids = output_token_ids.squeeze(dim=0).tolist() # remove batch size\n",
    "print(\"Output Text:\", tokenizer.decode(output_token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d465e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Text: Every effort moves his history withoutia Cro surprise pushed ax, with a _ so. forward enough him down, my work exquisitely on\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Every effort moves\"\n",
    "input_token_ids = tokenizer.encode(input_text)\n",
    "input_token_ids = torch.tensor(input_token_ids).unsqueeze(dim=0) # add batch dimension, BATCH_SIZE, SEQ_LENGTH\n",
    "output_token_ids = generate_text_sample_v3(model, input_token_ids,\n",
    "                                 max_new_tokens=25, context_size=GPT_CONFIG[\"context_length\"], \n",
    "                                 temperature=5)\n",
    "\n",
    "output_token_ids = output_token_ids.squeeze(dim=0).tolist() # remove batch size\n",
    "print(\"Output Text:\", tokenizer.decode(output_token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc740b0",
   "metadata": {},
   "source": [
    "### Load GPT-2 Small Pretrained Weights and Generate sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fc5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d776458e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: {'input_ids': tensor([[6109, 3626, 6100,  345]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n",
      "Encoded Tensor Shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "text = \"Every effort moves you\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(\"Encoded:\", encoded_input)\n",
    "print(\"Encoded Tensor Shape:\", encoded_input[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003a6667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every effort moves you forward.\\n\\nThe first step is to understand the importance of your work.\\n\\nThe second step is to understand the'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greedy Strategy\n",
    "output_tokens = model.generate(**encoded_input, max_new_tokens=25)\n",
    "tokenizer.decode(output_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "899206d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Every effort moves you towards being successful.\\n\\nIf it's not clear how long the effort will take (i.e., the task is\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens = model.generate(**encoded_input, max_new_tokens=25, top_k=10, temperature=1.5, do_sample=True)\n",
    "tokenizer.decode(output_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2c72a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Every effort moves you in an unexpected, sometimes surprising way. In our case it was to try and keep up with our family and friends, who'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens = model.generate(**encoded_input, max_new_tokens=25, top_k=10, temperature=1.5, do_sample=True)\n",
    "tokenizer.decode(output_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe2637",
   "metadata": {},
   "source": [
    "* As you can see, a lot better output of pretrained GPT-2 model trained on larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b29f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tti-model-inference-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
